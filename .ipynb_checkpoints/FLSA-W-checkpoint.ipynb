{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45171b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import nltk\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "# Load the data\n",
    "news_df = pd.read_csv('us_equities_news_dataset.csv') \n",
    "news_df['content'] = news_df['content'].fillna('')\n",
    "texts = news_df['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c85b19f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = simple_preprocess(text)  # Tokenization and lowercasing\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb5b1c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ticker                                              title release_date\n",
      "24        NIO  A Central Bank War Just Started And Its Good F...   2019-03-07\n",
      "32        NIO         6 Stocks To Watch  Nivida Could Be Falling   2019-03-06\n",
      "57        NIO  Stocks   Dow Drops Nearly 400 Points as Apple ...   2018-11-19\n",
      "78       UBER  The Zacks Analyst Blog Highlights  Advanced Mi...   2020-01-12\n",
      "82       UBER                     The Best Of CES 2020  Revised    2020-01-16\n",
      "...       ...                                                ...          ...\n",
      "221198    AMD  7 Tech Stocks With SMA50 Above SMA200 And High...   2012-12-07\n",
      "221202    AMD                           Deceased Rubber Felines    2012-11-25\n",
      "221229    PFE          Durata Therapeutics  DRTX  Pre IPO Report   2012-07-19\n",
      "221468      T  Zacks com Featured Highlights  AT T  Nu Skin E...   2016-07-21\n",
      "221471      T  5 Dividend Growth Stocks To Sail Through Uncer...   2016-07-20\n",
      "\n",
      "[7256 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Filter the news dataset for the articles that contain knowledge about NVidia.\n",
    "#These can be abbravations for Nvidia or just the name so this list contains words I'm searchinmg for in filtering the dataset\n",
    "#by checking if all content or title contain \"nvidia_terms\" list.\n",
    "nvidia_terms = [\n",
    "    'Nvidia', 'NVDA', 'N V D I A', 'Nvidia Corporation', 'NVIDIA Corp', \n",
    "    'NVIDIA GPUs', 'NVIDIA graphics', 'NVIDIA chip', 'NVIDIA cards', \n",
    "    'Nvidia GeForce', 'GeForce', 'Nvidia Quadro', 'NVIDIA AI', \n",
    "    'NVIDIA Tegra', 'Nvidia Drive', 'Nvidia RTX', 'RTX', \n",
    "    'NVIDIA DGX', 'NVIDIA Shield', 'CUDA', 'NVIDIA Jetson', \n",
    "    'NVIDIA Omniverse', 'NVIDIA Hopper', 'NVIDIA architecture',\n",
    "    'Nvidia hardware', 'Nvidia software', 'NVIDIA tech'\n",
    "]\n",
    "\n",
    "#Second filtering is applied to tickers to find the some companies that can affect the price. \n",
    "#My research shows AMD and Intel are the biggest competitors for Nvidia so I'm also including articles with ticker = 'AMD,INTC'\n",
    "filtered_news_df = news_df[\n",
    "    (news_df['title'].str.contains('|'.join(nvidia_terms), case=False, na=False)) |\n",
    "    (news_df['content'].str.contains('|'.join(nvidia_terms), case=False, na=False)) |\n",
    "    (news_df['ticker'].isin(['AMD', 'INTC']))  # Filter for AMD and Intel tickers\n",
    "]\n",
    "\n",
    "# Display the filtered DataFrame with Nvidia, AMD, and Intel related articles\n",
    "print(filtered_news_df[['ticker', 'title', 'release_date']])\n",
    "filtered_news_df = filtered_news_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38c5df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_news_df.to_csv('filtered_news_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a0e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_news_df['processed_text'] = filtered_news_df['content'].fillna('').apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c083d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24    [ecb, effect, move, euro, huge, falling, pip, ...\n",
       "32    [stock, watch, march, trading, session, stock,...\n",
       "57    [investing, com, rout, apple, facebook, nasdaq...\n",
       "78    [immediate, releasechicago, il, january, zacks...\n",
       "82    [company, bringing, innovation, ce, jan, get, ...\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_news_df['processed_text'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a14926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filterd_news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194c7525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'processed_text' is the column with lists of tokens\n",
    "all_tokens = sum(filtered_news_df['processed_text'], [])  # Flatten list of lists into a single list\n",
    "merged_string = ' '.join(all_tokens)  # Join all tokens into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a47bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Convert documents to a weighted TF-IDF matrix\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(merged_string)\n",
    "\n",
    "# Step 5: Apply Weighted LSA (FLSA-W Approximation) with TruncatedSVD\n",
    "n_topics = 5  # Adjust based on the number of topics you want\n",
    "svd_model = TruncatedSVD(n_components=n_topics, random_state=42)\n",
    "lsa_matrix = svd_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Step 6: Display Topics\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "for idx, topic in enumerate(svd_model.components_):\n",
    "    print(f\"Topic {idx + 1}: \", \" \".join([terms[i] for i in topic.argsort()[-10:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcab60f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_nlp_env] *",
   "language": "python",
   "name": "conda-env-my_nlp_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
